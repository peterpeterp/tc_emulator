{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SOM': <minisom.MiniSom object at 0x7fb35768dfd0>}\n",
      ".//ERA5_VWS-MSLP_noTC3/mapping_raw_1982-2020/SOM_pcaInit5x4_v1/mapping_sammon_1982-2020/grid_5x4\n"
     ]
    }
   ],
   "source": [
    "import sys,os,importlib,gc, re, string\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "os.chdir('/home/peter/Projects/tc_emulator/results')\n",
    "\n",
    "sys.path.append('../scripts')\n",
    "import _weather_pattern_class; importlib.reload(_weather_pattern_class)\n",
    "\n",
    "atl = _weather_pattern_class.weather_patterns(source='ERA5', working_directory='./')\n",
    "atl.load_input('ERA5_VWS-MSLP_noTC3')\n",
    "years = np.array(range(1982,2021))\n",
    "atl.set_split(years=years)\n",
    "nrows,ncols = 5,4\n",
    "tag = 'SOM_pcaInit%sx%s_v1' % (nrows,ncols)\n",
    "atl.define_plot_environment(pre_mapping='mapping_raw', clustering=tag, post_mapping='mapping_sammon_1982-2020', nrows=nrows, ncols=ncols)\n",
    "atl.stats_TC(file='tracks/tracks_ibtracks.csv', overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "years = np.arange(1982,2021,1)\n",
    "# get sst\n",
    "sst_MDR = xr.load_dataset('/home/peter/Projects/data/SST/OISST_sst_MDR_1981-2019_daily.nc')['sst']\n",
    "sst_MDR = sst_MDR[np.isin(sst_MDR.time.dt.year,years)]\n",
    "sst_MDR = sst_MDR[np.isin(sst_MDR.time.dt.month,atl._months['mon'])]\n",
    "sst_MDR = sst_MDR.assign_coords(time=np.array([str(d)[:10] for d in sst_MDR.time.values], np.datetime64))\n",
    "\n",
    "# prepare tracks:\n",
    "# here ssts are added. this will be needed in the wind component\n",
    "atl._tracks = atl._tracks.loc[np.isin(atl._tracks.year,years)]\n",
    "times = np.array([str(d)[:10] for d in atl._tracks.time.values], np.datetime64)\n",
    "atl._tracks['time'] = np.array([str(d)[:10] for d in atl._tracks.time],np.datetime64)\n",
    "atl._tracks['sst'] = sst_MDR.loc[times].values\n",
    "atl._tracks['weather_0'] = atl._tracks['label_lag0']\n",
    "tracks = atl._tracks.loc[np.isfinite(atl._tracks.weather_0)]\n",
    "tracks = tracks.loc[tracks.distance > 0, ['weather_0','sst','wind','genesis','storm','ACE','year','storm_day','wind_before','month']]\n",
    "\n",
    "# prepare gensis input\n",
    "# this is a dataframe with an entry for each day\n",
    "# this is required to get genesis probabilities\n",
    "weather_sst = pd.DataFrame()\n",
    "weather_sst['time'] =  np.array([str(d)[:10] for d in  atl._vector_time.values], np.datetime64)\n",
    "weather_sst['year'] = atl._vector_time.dt.year\n",
    "weather_sst['weather_0'] = atl._clust_labels\n",
    "weather_sst['weather_1'] = np.roll(atl._clust_labels,1)\n",
    "weather_sst['weather_2'] = np.roll(atl._clust_labels,2)\n",
    "weather_sst['weather_3'] = np.roll(atl._clust_labels,3)\n",
    "weather_sst = weather_sst.loc[np.isin(atl._vector_time.dt.year,years)]\n",
    "\n",
    "genesis = weather_sst.copy()\n",
    "genesis['genesis'] = [atl._tracks.loc[atl._tracks.time==np.datetime64(tt),'genesis'].sum() for tt in genesis.time]\n",
    "genesis['sst'] = sst_MDR.sel(time=weather_sst.time.values)\n",
    "\n",
    "weather_sst['sst'] = sst_MDR.sel(time=weather_sst.time.values)\n",
    "\n",
    "genesis['day_in_season'] = 0\n",
    "weather_sst['day_in_season'] = 0\n",
    "for year in np.unique(weather_sst.time.dt.year):\n",
    "    tttmmmppp = weather_sst.loc[(weather_sst.time.dt.year==year),'day_in_season']\n",
    "    weather_sst.loc[(weather_sst.time.dt.year==year),'day_in_season'] = np.arange(tttmmmppp.shape[0])\n",
    "    genesis.loc[(genesis.time.dt.year==year),'day_in_season'] = np.arange(tttmmmppp.shape[0])\n",
    "\n",
    "weather_sst = weather_sst.loc[(weather_sst.day_in_season>=3) & np.isin(weather_sst.year,years)]\n",
    "genesis = genesis.loc[(genesis.day_in_season>=3) & np.isin(genesis.year,years)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(454,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(tracks.storm).shape\n",
    "# tracks.genesis.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# train test split by decades\n",
    "train_test = pd.DataFrame()\n",
    "train_test['year'] = list(range(1982,2021))\n",
    "train_test['1982-1990'] = 'train'\n",
    "train_test.loc[np.isin(train_test.year,np.arange(1982,1990+1)), '1982-1990'] = 'test'\n",
    "train_test['1991-2000'] = 'train'\n",
    "train_test.loc[np.isin(train_test.year,np.arange(1991,2000+1)), '1991-2000'] = 'test'\n",
    "train_test['2001-2010'] = 'train'\n",
    "train_test.loc[np.isin(train_test.year,np.arange(2001,2010+1)), '2001-2010'] = 'test'\n",
    "train_test['2011-2020'] = 'train'\n",
    "train_test.loc[np.isin(train_test.year,np.arange(2011,2020+1)), '2011-2020'] = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "comp_names = {\n",
    "    'gWeaLag2Weight' : '',\n",
    "    'gWeaLag2' : 'equal weight',\n",
    "    'gWea' : 'no lag',\n",
    "    'gnnWeaSST' : 'NN weather + SST',\n",
    "    'sLWeaNeigh' : '',\n",
    "    'sLWea' : 'no neighbors',\n",
    "    'sLAll' : 'random',\n",
    "    'wS100nnQrSST' : '',\n",
    "    'wS100nn' : '100 nn',\n",
    "    'wS50nn' : '50 nn',\n",
    "    'wS20nn' : '20 nn',\n",
    "    'wS100nnNoSST' : 'no SST',\n",
    "    'wS100nnQrSSTnoHist' : 'no history',\n",
    "    'wS100nnQrSSTnoWeather' : 'no weather',\n",
    "    'g' : 'formation',\n",
    "    'sL' : 'duration',\n",
    "    'wS': 'intensification'\n",
    "}\n",
    "\n",
    "def siggi(s):\n",
    "    if np.isnan(s): return ''\n",
    "    if s < 0.1: return '*'\n",
    "    #if s < 0.1: return '*'\n",
    "    return ''\n",
    "\n",
    "def nicer_plot(fig, ax, out_file, ylim=None, upper_left='', upper_right='', edgeC='w', text=''):\n",
    "    ax.annotate(upper_left, xy=(0.03,0.95), xycoords='figure fraction', ha='left', va='top', fontweight='bold', fontsize=12, backgroundcolor='w')\n",
    "    ax.annotate(upper_right, xy=(0.97,0.97), xycoords='figure fraction', ha='right', va='top', fontweight='bold', fontsize=12, color=edgeC, backgroundcolor='w')\n",
    "    ax.annotate(text, xy=(0.03,0.97), xycoords='axes fraction', ha='left', va='top', backgroundcolor='none')\n",
    "    if ylim is None:\n",
    "        ylim = ax.get_ylim()\n",
    "    ax.set_ylim(ylim)\n",
    "    plt.gcf().patch.set_linewidth(3)\n",
    "    plt.savefig(out_file, bbox_inches='tight', dpi=200, edgecolor=edgeC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# choose components\n",
    "alphabet = iter(list(string.ascii_uppercase))\n",
    "alphabet_sL = iter(list(string.ascii_uppercase))\n",
    "alphabet_wS = iter(list(string.ascii_uppercase))\n",
    "version = iter(range(1,100))\n",
    "comps_todo = [\n",
    "    {'g':'gWeaLag2Weight', 'sL':'sLWeaNeigh', 'wS':'wS100nnQrSST', 'Emu':'Emu0', 'name':'main','l':next(alphabet),'c':'c', 'v':'main', 'vc':''},\n",
    "    ]\n",
    "for i,g in enumerate(['gWea', 'gWeaLag2', 'gnnWeaSST']):\n",
    "    comps_todo.append({'g':g, 'sL':'sLWeaNeigh', 'wS':'wS100nnQrSST', 'Emu':'Emu0', 'name':'formation: '+comp_names[g],'l':next(alphabet),'c':'m', 'v':'v%s' %(next(version)), 'vc':'vG%s' %(i)})\n",
    "for i,sL in enumerate(['sLAll','sLWea']):\n",
    "    comps_todo.append({'g':'gWeaLag2Weight', 'sL':sL, 'wS':'wS100nnQrSST', 'Emu':'Emu0', 'name':'duration: '+comp_names[sL],'l':next(alphabet),'c':'orange', 'v':'v%s' %(next(version)), 'vc':'vD%s' %(i)})\n",
    "for i,wS in enumerate(['wS100nn','wS20nn','wS100nnNoSST','wS100nnQrSSTnoWeather','wS100nnQrSSTnoHist']):\n",
    "    # for i,wS in enumerate(['wS20nn','wS50nn','wS100nn'][::-1]):\n",
    "    comps_todo.append({'g':'gWeaLag2Weight', 'sL':'sLWeaNeigh', 'wS':wS, 'Emu':'Emu0', 'name':'intensification: '+comp_names[wS],'l':next(alphabet),'c':'r', 'v':'v%s' %(next(version)), 'vc':'vI%s' %(i)})\n",
    "N = 1000\n",
    "overwrite = False\n",
    "validations = {}\n",
    "for dt in comps_todo:\n",
    "    tag = '_'.join([dt[k] for k in ['g','sL','wS','Emu']])\n",
    "    print(tag)\n",
    "    import _emulator; importlib.reload(_emulator); from _emulator import *\n",
    "    for k,v in {k:v for k,v in dt.items() if k in ['g','sL','wS','Emu']}.items():\n",
    "        exec(\"import %s; importlib.reload(%s); from %s import *\" % tuple(['components.'+k+'.'+v]*3))\n",
    "    for test_period in [tt for tt in train_test.columns if tt != 'year']:\n",
    "        train_years = train_test.loc[train_test[test_period]=='train', 'year'].values\n",
    "        test_years = train_test.loc[train_test[test_period]=='test', 'year'].values\n",
    "        train_folder = atl._dir_lvl4 + '/emulator/' + str(test_period)+'/'\n",
    "        # genesis\n",
    "        comp_file = train_folder+'/_comp_g_'+dt['g']+'/genesis_obj.pkl'\n",
    "        if os.path.isfile(comp_file) and overwrite == False:\n",
    "            genesis_obj = pickle.load(open(comp_file, 'rb'))\n",
    "        else:\n",
    "            genesis_obj = genesis_pred(dir=train_folder+'/_comp_g_'+dt['g']+'/', df=genesis.loc[np.isin(genesis.time.dt.year,train_years)])\n",
    "            genesis_obj.fit(atl)\n",
    "            genesis_obj.save()\n",
    "            # print(genesis_obj._probs)\n",
    "        # stormLength\n",
    "        comp_file = train_folder+'/_comp_sL_'+dt['sL']+'/end_obj.pkl'\n",
    "        if os.path.isfile(comp_file) and overwrite == False:\n",
    "            stormL_obj = pickle.load(open(comp_file, 'rb'))\n",
    "        else:\n",
    "            stormL_obj = storm_length_estimator(dir=train_folder+'/_comp_sL_'+dt['sL']+'/', atl=atl, tracks=tracks.loc[np.isin(tracks.year,train_years)])\n",
    "            stormL_obj.save()\n",
    "            stormL_obj.plot_simulated_storm_length(atl=atl, tracks=tracks.loc[np.isin(tracks.year,train_years)])\n",
    "        # windSpeed\n",
    "        comp_file = train_folder+'/_comp_wS_'+dt['wS']+'/wind_obj.pkl'\n",
    "        if os.path.isfile(comp_file) and overwrite == False:\n",
    "            wind_obj = pickle.load(open(comp_file, 'rb'))\n",
    "            # quantiles, wind_quR_params = sst_vs_wind_quantile_regression(tracks.loc[np.isin(tracks.year,train_years)], plot_dir=train_folder+'/_comp_wS_'+dt['wS']+'/', sst_var='sst')\n",
    "\n",
    "        else:\n",
    "            wind_obj = wind_estimator(dir=train_folder+'/_comp_wS_'+dt['wS']+'/', df=tracks.loc[np.isin(tracks.year,train_years)])\n",
    "            wind_obj.get_analogue_pdfs(atl=atl)\n",
    "            wind_obj.load_pdfs()\n",
    "            wind_obj.save()\n",
    "        exec(\"import %s; importlib.reload(%s); from %s import *\" % tuple(['components.wS._helping_functions']*3))\n",
    "        quantiles, wind_quR_params = sst_vs_wind_quantile_regression(tracks.loc[np.isin(tracks.year,train_years)], plot_dir=train_folder+'/_comp_wS_'+dt['wS']+'/', sst_var='sst')\n",
    "        # print(wind_obj._lr)\n",
    "        # wind_obj.plot_pdfs()\n",
    "        emu = storm_emulator(dir=train_folder, tag=tag, emulate_season_function=emulate_season_function)\n",
    "        atl._vector_time.values = np.array([str(d)[:10] for d in atl._vector_time.values], np.datetime64)\n",
    "        # emu.prepare_input(atl, sst_tropics, sst_MDR_rel, years, fileName = atl._dir_lvl4 + '/emulator/weather_sst_input.csv', overwrite=overwrite)\n",
    "        emu._weather_sst = weather_sst\n",
    "        emu.emulate_seasons_serial(genesis_obj, wind_obj, stormL_obj, years=test_years, N=N, overwrite=overwrite)\n",
    "    emu = storm_emulator(dir=atl._dir_lvl4 + '/emulator/xValid/', tag=tag, emulate_season_function=None)\n",
    "    emu._seasons = {}\n",
    "    for test_period in [tt for tt in train_test.columns if tt != 'year']:\n",
    "        test_years = train_test.loc[train_test[test_period]=='test', 'year'].values\n",
    "        for test_year in test_years:\n",
    "            with open(atl._dir_lvl4 + '/emulator/'+test_period+'/'+tag+'/sim/'+tag+'_'+str(test_year)+'_N'+str(N)+'.pkl', 'rb') as infile:\n",
    "                emu._seasons[test_year] = pickle.load(infile)\n",
    "    emu._N = N\n",
    "    emu._weather_sst = weather_sst\n",
    "    # emu.get_simu_tracks(overwrite=True)\n",
    "    # emu.get_other_stats_for_tracks(tracks)\n",
    "    emu.get_stats_seasonal_simu(overwrite=False)\n",
    "    emu.get_stats_seasonal_obs(tracks, train_test.year.values)\n",
    "    emu._sets = [{'years':[years], 'label':'xValid', 'color':'c'}]\n",
    "    emu._indicator_dict = {\n",
    "        'genesis' : 'storm formations',\n",
    "        'storm_days' : 'storm days in season',\n",
    "        'wind' : 'max. daily wind speed',\n",
    "        'wind' : 'acc. daily max. wind speeds',\n",
    "        'ACE' : 'ACE',\n",
    "        'Hur' : 'hurricanes',\n",
    "        'MajHur' : 'major hurricanes',\n",
    "        'stoMaxWind' : 'max. intensity of storm [kts]',\n",
    "        'stoLen' : 'storm duration',\n",
    "        'stoD' : 'day of storm',\n",
    "        'dWind' : 'change in storm intensity [kts]',\n",
    "        'wind_before' : 'intensity on the day before',\n",
    "        'sst' : 'SST',\n",
    "    }\n",
    "    if tag == 'gWeaLag2Weight_sLWeaNeigh_wS100nnQrSST_Emu0':\n",
    "        # fig 3\n",
    "        axes_ = []\n",
    "        fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(8,5), sharex=True)\n",
    "        for indicator,letter,ylim,ax in zip(['genesis','storm_days','MajHur','ACE', 'Hur'],['A','B','C','D','E'],[(0,30),(0,200),(0,10),(0,350),(0,16)], axes.flatten()):\n",
    "            ax = emu.vali_year_to_year_variability(indicator, show_legend=False, ax=ax)\n",
    "            ax.annotate(letter, xy=(0.05,0.95), xycoords='axes fraction', ha='left', va='top', fontweight='bold', fontsize=12, backgroundcolor='w')\n",
    "            corr_ = 'corr: %.2f%s' %(emu._validation[indicator]['pearson_median']['coef'],siggi(emu._validation[indicator]['pearson_median']['pval']))\n",
    "            ax.annotate(corr_, xy=(0.95,0.95), xycoords='axes fraction', ha='right', va='top', fontweight='bold', fontsize=12, backgroundcolor='w')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(emu._dir_plot+'fig3.png', dpi=300)\n",
    "\n",
    "\n",
    "    if dt['sL'] != 'sLWeaNeigh' or tag == 'gWeaLag2Weight_sLWeaNeigh_wS100nnQrSST_Emu0':\n",
    "        letter_ = next(alphabet_sL)\n",
    "\n",
    "        storms = [[np.float(w) for w in tracks.loc[(tracks.storm==storm), 'wind']] for storm in np.unique(tracks.loc[np.isin(tracks.year,years),'storm'])]\n",
    "        seasons = [winds for season in emu._seasons.values() for storms in season for winds in storms.values()]\n",
    "        \n",
    "        # HIST #\n",
    "        out_file = emu._dir_plot+'hist_duration_N'+str(emu._N)+'.png'\n",
    "        if os.path.isfile(out_file.replace('.png','.pkl')) and False:\n",
    "            fig, ax = pickle.load(open(out_file.replace('.png','.pkl'),'rb'))\n",
    "        else:\n",
    "            obs = np.array([len(winds) for winds in storms])\n",
    "            simu = np.array([len(winds) for winds in seasons])\n",
    "            fig, ax, out_file = emu.vali_distr_tests(obs=obs, simu=simu, out_file=out_file, indicator='duration', bins=np.arange(0,30,1))\n",
    "            pickle.dump((fig,ax), open(out_file.replace('.png','.pkl'), 'wb'))\n",
    "        ax.set_xlabel('storm duration [days]')\n",
    "        nicer_plot(fig,ax,out_file.replace('.png','_sens.png'), upper_left=letter_, upper_right=dt['name'], edgeC=dt['c'])\n",
    "\n",
    "\n",
    "    version_text = '\\n'.join(['%s: %s' %(comp_names[k],comp_names[dt[k]]) for k in ['g','sL','wS']])\n",
    "    for indicator,ylim in zip(['genesis','storm_days','Hur','MajHur','ACE'],[(0,35),(0,220),(0,18),(0,12),(0,360)]):\n",
    "        # Year to Year and correlation #\n",
    "        fig,ax,out_file = emu.vali_year_to_year_variability(indicator, show_legend=False)\n",
    "        vali = emu._validation[indicator]\n",
    "        text = 'pearson corr.: %s%s' %(vali['pearson_mean']['coef'].round(2), siggi(vali['pearson_mean']['pval']))\n",
    "        text += '\\nspearman corr.: %s%s' %(vali['spearman_mean']['coef'].round(2), siggi(vali['spearman_mean']['pval']))\n",
    "        nicer_plot(fig,ax,out_file.replace('.png','_sens.png'), ylim=ylim, text=text)\n",
    "    for indicator,ylim in zip(['genesis','storm_days','MajHur','ACE', 'Hur'],[(-16,16),(-120,120),(-7,7),(-240,240),(-10,10)]):\n",
    "        # trend in residuals #\n",
    "        fig,ax,out_file = emu.vali_residuals_and_long_term_trend(indicator)\n",
    "        vali = emu._validation[indicator]\n",
    "        text = 'MannKendall: %s%s' %(vali['MK_mean']['trend'], siggi(vali['MK_mean']['pval']))\n",
    "        text += '\\nLinear trend: %s%s' %(vali['trend_mean']['slope'].round(2), siggi(vali['trend_mean']['pval']))\n",
    "        nicer_plot(fig,ax,out_file.replace('.png','_sens.png'), ylim=ylim, text=text)\n",
    "\n",
    "        # RMSD\n",
    "        emu.vali_RMSD(indicator)\n",
    "\n",
    "    # residuals vs SST \n",
    "    for indicator,ylim in zip(['genesis','storm_days','MajHur','ACE', 'Hur'],[(-16,16),(-120,120),(-7,7),(-240,240),(-10,10)]):\n",
    "        fig,ax,out_file = emu.vali_residuals_IND_vs_SST(indicator, sst_MDR.groupby('time.year').mean('time'))\n",
    "        vali = emu._validation[indicator]\n",
    "        text = 'MannKendall: %s%s' %(vali['MK_vs_SST_median']['trend'], siggi(vali['MK_vs_SST_median']['pval']))\n",
    "        text += '\\nLinear regression: %s%s' %(vali['trend_vs_SST_median']['slope'].round(2), siggi(vali['trend_vs_SST_median']['pval']))\n",
    "        nicer_plot(fig,ax,out_file.replace('.png','_sens.png'), ylim=ylim, text=text)\n",
    "\n",
    "    if dt['wS'] != 'wS100nnQrSST' or tag == 'gWeaLag2Weight_sLWeaNeigh_wS100nnQrSST_Emu0':\n",
    "        #####################\n",
    "        # deviations in KNN #\n",
    "        #####################\n",
    "        for var,ylim,xlim in zip(['wind_before','sst'],[(-100,40),(-0.5,0.5)],[(0,160),(27,29)]):\n",
    "            plt.close('all')\n",
    "            fig,ax = plt.subplots(nrows=1, figsize=(4,3))\n",
    "            dists = xr.open_dataset(train_folder+'/_comp_wS_'+dt['wS']+'/distances.nc')['distances']          \n",
    "            if var in dists.dims:\n",
    "                for weather in [15,6,1,12]:\n",
    "                    y = dists.sel({'q':[17,50,83],'d':var}).squeeze()\n",
    "                    if 'weather_0' in dists.dims:\n",
    "                        y = y.sel({'weather_0':weather})\n",
    "                    for k in [k for k in y.dims if k not in [var,'q']]:\n",
    "                        y = y.mean(k)\n",
    "                    ax.fill_between(dists[var], y.loc[:,17], y.loc[:,83], alpha=0.5)\n",
    "                    ax.plot(dists[var], y.loc[:,50], label='w%s' %(weather))\n",
    "                ax.set_ylabel('bias in \\n'+emu._indicator_dict[var])\n",
    "                ax.set_xlabel(emu._indicator_dict[var])\n",
    "                ax.legend()\n",
    "                ax.set_xlim(xlim)\n",
    "                out_file = train_folder+'/_comp_wS_'+dt['wS']+'/dist_weather_'+var+'.png'\n",
    "                nicer_plot(fig,ax,out_file.replace('.png','_sens.png'), ylim=ylim)\n",
    "                # nicer_plot(fig,ax,out_file.replace('.png','_sens.png'), ylim=ylim, upper_left=letter_, upper_right=dt['vc'], edgeC=dt['c'])\n",
    "    \n",
    "    validations[tag] = emu._validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validations['gWeaLag2Weight_sLWeaNeigh_wS100nnQrSST_Emu0']['MajHur']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validations['gWeaLag2Weight_sLWeaNeigh_wS100nnNoSST_Emu0']['ACE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## old\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # # residuals vs ACE \n",
    "    # fig,ax,out_file = emu.vali_residuals_IND_vs_X('ACE', emu._obs['ACE'], 'ACE')\n",
    "    # nicer_plot(fig,ax,out_file.replace('.png','_sens.png'), upper_left=dt['l'], upper_right=dt['name'], edgeC=dt['c'])\n",
    "    # if dt['wS'] != 'wS100nnQrSST' or tag == 'gWeaLag2Weight_sLWeaNeigh_wS100nnQrSST_Emu0':\n",
    "    #     #####################\n",
    "    #     # deviations in KNN #\n",
    "    #     #####################\n",
    "    #     for var,ylim,xlim in zip(['wind_before','sst'],[(-100,40),(-0.5,0.5)],[(0,160),(27,29)]):\n",
    "    #         plt.close('all')\n",
    "    #         fig,ax = plt.subplots(nrows=1, figsize=(4,3))\n",
    "    #         dists = xr.open_dataset(train_folder+'/_comp_wS_'+dt['wS']+'/distances.nc')['distances']\n",
    "    #         if var in dists.dims:\n",
    "    #             for weather in [0,12,6,10,15]:\n",
    "    #                 y = dists.sel({'q':[17,50,83],'d':var}).squeeze()\n",
    "    #                 if 'weather_0' in dists.dims:\n",
    "    #                     y = y.sel({'weather_0':weather})\n",
    "    #                 for k in [k for k in y.dims if k not in [var,'q']]:\n",
    "    #                     y = y.mean(k)\n",
    "    #                 ax.fill_between(dists[var], y.loc[:,17], y.loc[:,83], alpha=0.5)\n",
    "    #                 ax.plot(dists[var], y.loc[:,50], label='w%s' %(weather))\n",
    "    #             ax.set_ylabel('bias in '+emu._indicator_dict[var])\n",
    "    #             ax.set_xlabel(emu._indicator_dict[var])\n",
    "    #             ax.legend()\n",
    "    #             ax.set_xlim(xlim)\n",
    "    #             out_file = train_folder+'/_comp_wS_'+dt['wS']+'/dist_weather_'+var+'.png'\n",
    "    #             nicer_plot(fig,ax,out_file.replace('.png','_sens.png'), ylim=ylim, upper_left=dt['l'], upper_right=dt['name'], edgeC='k')\n",
    "    #             # nicer_plot(fig,ax,out_file.replace('.png','_sens.png'), ylim=ylim, upper_left=letter_, upper_right=dt['vc'], edgeC=dt['c'])\n",
    "    \n",
    "    # # residuals vs SSTs  #\n",
    "    # for indicator,lim in zip(['wind','ACE','Hur','MajHur','genesis'],[(-6000,6000),(-200,200),(-10,10),(-6,6),(-15,15)]):\n",
    "    #     fig,ax,out_file = emu.vali_residuals_IND_vs_SST(indicator, sst_MDR.groupby('time.year').mean('time'))\n",
    "    #     nicer_plot(fig,ax,out_file.replace('.png','_sens.png'), upper_left=dt['l'], upper_right=dt['name'], edgeC=dt['c'])\n",
    "\n",
    "    \n",
    "    \n",
    "    print(emu._validation['ACE']['trend_median'], emu._validation['ACE']['trend_mean'])\n",
    "\n",
    "    if dt['wS'] != 'wS100nnQrSST' or tag == 'gWeaLag2Weight_sLWeaNeigh_wS100nnQrSST_Emu0':\n",
    "        print('wind plots', dt['wS'])\n",
    "        letter_ = next(alphabet_wS)\n",
    "\n",
    "        storms = [[np.float(w) for w in tracks.loc[(tracks.storm==storm), 'wind']] for storm in np.unique(tracks.loc[np.isin(tracks.year,years),'storm'])]\n",
    "        seasons = [winds for season in emu._seasons.values() for storms in season for winds in storms.values()]\n",
    "\n",
    "        # max. wind vs storm length #stoMaxWind_vs_stoLen_N1000_sens.png\n",
    "        out_file = emu._dir_plot+'hstoMaxWind_vs_stoLen_N%s.png' %(emu._N)\n",
    "        if os.path.isfile(out_file.replace('.png','.pkl')):\n",
    "            fig, ax, im_simu, im_obs = pickle.load(open(out_file.replace('.png','.pkl'),'rb'))\n",
    "        else:\n",
    "            stoLen = np.array([len(winds) for winds in storms])\n",
    "            maxWind = np.array([max(winds) for winds in storms])\n",
    "            obs = pd.DataFrame(np.vstack((stoLen,maxWind)).T, columns=('stoLen','stoMaxWind'))\n",
    "            stoLen = np.array([len(winds) for winds in seasons])\n",
    "            maxWind = np.array([max(winds) for winds in seasons])\n",
    "            simu = pd.DataFrame(np.vstack((stoLen,maxWind)).T)\n",
    "            fig, ax, im_simu, im_obs, _ = emu.vali_2D_distr_plot(obs,simu, ranges=[0,14,0,120], bw_method=0.2, nBins=50)\n",
    "            pickle.dump((fig,ax,im_simu,im_obs), open(out_file.replace('.png','.pkl'), 'wb'))\n",
    "        nicer_plot(fig,ax,out_file.replace('.png','_sens.png'), upper_left=letter_, upper_right=dt['name'], edgeC=dt['c'])\n",
    "        # fig, ax, out_file = emu.vali_2D_distr_KL_divergence(obs,simu, ranges=[np.arange(0.5,14.5,1),np.arange(15,115,10)])\n",
    "\n",
    "        # daily wind speed vs storm day #\n",
    "        out_file = emu._dir_plot+'stoD_vs_wind_N%s.png' %(emu._N)\n",
    "        if os.path.isfile(out_file.replace('.png','.pkl')):\n",
    "            fig, ax, im_simu, im_obs = pickle.load(open(out_file.replace('.png','.pkl'),'rb'))\n",
    "        else:\n",
    "            stoDay = np.array([i for winds in storms for i in range(len(winds))])\n",
    "            wind = np.array([w for winds in storms for w in winds]).flatten()\n",
    "            obs = pd.DataFrame(np.vstack((stoDay,wind)).T, columns=('stoD','wind'))\n",
    "            stoDay = np.array([i for winds in seasons for i in range(len(winds))]).flatten()\n",
    "            wind = np.array([w for winds in seasons for w in winds]).flatten()\n",
    "            simu = pd.DataFrame(np.vstack((stoDay,wind)).T)\n",
    "            fig, ax, im_simu, im_obs, _ = emu.vali_2D_distr_plot(obs,simu, ranges=[0,10,0,100], bw_method=0.2, nBins=50)\n",
    "            pickle.dump((fig,ax,im_simu,im_obs), open(out_file.replace('.png','.pkl'), 'wb'))\n",
    "        nicer_plot(fig,ax,out_file.replace('.png','_sens.png'), upper_left=letter_, upper_right=dt['name'], edgeC=dt['c'])\n",
    "        # fig, ax, out_file = emu.vali_2D_distr_KL_divergence(obs,simu, ranges=[np.arange(0.5,10.5,1),np.arange(5,105,10)])\n",
    "\n",
    "        # daily change in wind speed vs storm day #\n",
    "        out_file = emu._dir_plot+'stoD_vs_dWind_N%s.png' %(emu._N)\n",
    "        if os.path.isfile(out_file.replace('.png','.pkl')):\n",
    "            fig, ax, im_simu, im_obs = pickle.load(open(out_file.replace('.png','.pkl'),'rb'))\n",
    "        else:\n",
    "            stoDay = np.array([i+2 for winds in storms for i in range(len(winds)-1)])\n",
    "            wind = np.array([w-winds[i-1] for winds in storms for i,w in enumerate(winds[1:])]).flatten()\n",
    "            obs = pd.DataFrame(np.vstack((stoDay,wind)).T, columns=('stoD','dWind'))\n",
    "            stoDay = np.array([i+2 for winds in seasons for i in range(len(winds)-1)]).flatten()\n",
    "            wind = np.array([w-winds[i-1] for winds in seasons for i,w in enumerate(winds[1:])]).flatten()\n",
    "            simu = pd.DataFrame(np.vstack((stoDay,wind)).T)\n",
    "            fig, ax, im_simu, im_obs, _ = emu.vali_2D_distr_plot(obs,simu, ranges=[0,10,-50,50], bw_method=0.2, nBins=50)\n",
    "            pickle.dump((fig,ax,im_simu,im_obs), open(out_file.replace('.png','.pkl'), 'wb'))\n",
    "        nicer_plot(fig,ax,out_file.replace('.png','_sens.png'), upper_left=letter_, upper_right=dt['name'], edgeC=dt['c'])\n",
    "        # fig, ax, out_file = emu.vali_2D_distr_KL_divergence(obs,simu, ranges=[np.arange(0.5,10.5,1),np.arange(-55,65,10)])\n",
    "\n",
    "        # # outliers #\n",
    "        # fig,ax,out_file = emu.vali_outliers(indicator)\n",
    "        # nicer_plot(fig,ax,out_file.replace('.png','_sens.png'), upper_left=dt['l'], ylim=(0,111), edgeC=dt['c'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os,importlib,gc, re, string\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "os.chdir('/home/peter/Projects/tc_emulator/results')\n",
    "\n",
    "sys.path.append('../scripts')\n",
    "import _weather_pattern_class; importlib.reload(_weather_pattern_class)\n",
    "\n",
    "atl = _weather_pattern_class.weather_patterns(source='ERA5', working_directory='./')\n",
    "atl.load_input('ERA5_VWS-MSLP_noTC3')\n",
    "years = np.array(range(1982,2021))\n",
    "atl.set_split(years=years)\n",
    "nrows,ncols = 5,4\n",
    "tag = 'SOM_pcaInit%sx%s_v1' % (nrows,ncols)\n",
    "atl.define_plot_environment(pre_mapping='mapping_raw', clustering=tag, post_mapping='mapping_sammon_1982-2020', nrows=nrows, ncols=ncols)\n",
    "atl.stats_TC(file='tracks/tracks_ibtracks.csv', overwrite=False)\n",
    "\n",
    "years = np.arange(1982,2021,1)\n",
    "# get sst\n",
    "sst_MDR = xr.load_dataset('/home/peter/Projects/data/SST/OISST_sst_MDR_1981-2019_daily.nc')['sst']\n",
    "sst_MDR = sst_MDR[np.isin(sst_MDR.time.dt.year,years)]\n",
    "sst_MDR = sst_MDR[np.isin(sst_MDR.time.dt.month,atl._months['mon'])]\n",
    "sst_MDR = sst_MDR.assign_coords(time=np.array([str(d)[:10] for d in sst_MDR.time.values], np.datetime64))\n",
    "\n",
    "# prepare tracks:\n",
    "# here ssts are added. this will be needed in the wind component\n",
    "atl._tracks = atl._tracks.loc[np.isin(atl._tracks.year,years)]\n",
    "times = np.array([str(d)[:10] for d in atl._tracks.time.values], np.datetime64)\n",
    "atl._tracks['time'] = np.array([str(d)[:10] for d in atl._tracks.time],np.datetime64)\n",
    "atl._tracks['sst'] = sst_MDR.loc[times].values\n",
    "atl._tracks['weather_0'] = atl._tracks['label_lag0']\n",
    "tracks = atl._tracks.loc[np.isfinite(atl._tracks.weather_0)]\n",
    "tracks = tracks.loc[tracks.distance > 0, ['weather_0','sst','wind','genesis','storm','ACE','year','storm_day','wind_before','month']]\n",
    "\n",
    "# prepare gensis input\n",
    "# this is a dataframe with an entry for each day\n",
    "# this is required to get genesis probabilities\n",
    "weather_sst = pd.DataFrame()\n",
    "weather_sst['time'] =  np.array([str(d)[:10] for d in  atl._vector_time.values], np.datetime64)\n",
    "weather_sst['year'] = atl._vector_time.dt.year\n",
    "weather_sst['weather_0'] = atl._clust_labels\n",
    "weather_sst['weather_1'] = np.roll(atl._clust_labels,1)\n",
    "weather_sst['weather_2'] = np.roll(atl._clust_labels,2)\n",
    "weather_sst['weather_3'] = np.roll(atl._clust_labels,3)\n",
    "weather_sst = weather_sst.loc[np.isin(atl._vector_time.dt.year,years)]\n",
    "\n",
    "genesis = weather_sst.copy()\n",
    "genesis['genesis'] = [atl._tracks.loc[atl._tracks.time==np.datetime64(tt),'genesis'].sum() for tt in genesis.time]\n",
    "genesis['sst'] = sst_MDR.sel(time=weather_sst.time.values)\n",
    "\n",
    "weather_sst['sst'] = sst_MDR.sel(time=weather_sst.time.values)\n",
    "\n",
    "genesis['day_in_season'] = 0\n",
    "weather_sst['day_in_season'] = 0\n",
    "for year in np.unique(weather_sst.time.dt.year):\n",
    "    tttmmmppp = weather_sst.loc[(weather_sst.time.dt.year==year),'day_in_season']\n",
    "    weather_sst.loc[(weather_sst.time.dt.year==year),'day_in_season'] = np.arange(tttmmmppp.shape[0])\n",
    "    genesis.loc[(genesis.time.dt.year==year),'day_in_season'] = np.arange(tttmmmppp.shape[0])\n",
    "\n",
    "weather_sst = weather_sst.loc[(weather_sst.day_in_season>=3) & np.isin(weather_sst.year,years)]\n",
    "genesis = genesis.loc[(genesis.day_in_season>=3) & np.isin(genesis.year,years)]\n",
    "\n",
    "# train test split by decades\n",
    "train_test = pd.DataFrame()\n",
    "train_test['year'] = list(range(1982,2021))\n",
    "train_test['1982-1990'] = 'train'\n",
    "train_test.loc[np.isin(train_test.year,np.arange(1982,1990+1)), '1982-1990'] = 'test'\n",
    "train_test['1991-2000'] = 'train'\n",
    "train_test.loc[np.isin(train_test.year,np.arange(1991,2000+1)), '1991-2000'] = 'test'\n",
    "train_test['2001-2010'] = 'train'\n",
    "train_test.loc[np.isin(train_test.year,np.arange(2001,2010+1)), '2001-2010'] = 'test'\n",
    "train_test['2011-2020'] = 'train'\n",
    "train_test.loc[np.isin(train_test.year,np.arange(2011,2020+1)), '2011-2020'] = 'test'\n",
    "\n",
    "comp_names = {\n",
    "    'gWeaLag2Weight' : '',\n",
    "    'gWeaLag2' : 'equal weight',\n",
    "    'gWea' : 'no lag',\n",
    "    'gnnWeaSST' : 'NN weather + SST',\n",
    "    'sLWeaNeigh' : '',\n",
    "    'sLWea' : 'no neighbors',\n",
    "    'sLAll' : 'random',\n",
    "    'wS100nnQrSST' : '',\n",
    "    'wS100nn' : '100 nn',\n",
    "    'wS50nn' : '50 nn',\n",
    "    'wS20nn' : '20 nn',\n",
    "    'wS100nnNoSST' : 'no SST',\n",
    "    'wS100nnQrSSTnoHist' : 'no history',\n",
    "    'wS100nnQrSSTnoWeather' : 'no weather',\n",
    "    'g' : 'formation',\n",
    "    'sL' : 'duration',\n",
    "    'wS': 'intensification'\n",
    "}\n",
    "\n",
    "def siggi(s):\n",
    "    if np.isnan(s): return ''\n",
    "    if s < 0.1: return '*'\n",
    "    #if s < 0.1: return '*'\n",
    "    return ''\n",
    "\n",
    "def nicer_plot(fig, ax, out_file, ylim=None, upper_left='', upper_right='', edgeC='w', text=''):\n",
    "    ax.annotate(upper_left, xy=(0.03,0.95), xycoords='figure fraction', ha='left', va='top', fontweight='bold', fontsize=12, backgroundcolor='w')\n",
    "    ax.annotate(upper_right, xy=(0.97,0.97), xycoords='figure fraction', ha='right', va='top', fontweight='bold', fontsize=12, color=edgeC, backgroundcolor='w')\n",
    "    ax.annotate(text, xy=(0.03,0.97), xycoords='axes fraction', ha='left', va='top', backgroundcolor='none')\n",
    "    if ylim is None:\n",
    "        ylim = ax.get_ylim()\n",
    "    ax.set_ylim(ylim)\n",
    "    plt.gcf().patch.set_linewidth(3)\n",
    "    plt.savefig(out_file, bbox_inches='tight', dpi=200, edgecolor=edgeC)\n",
    "\n",
    "\n",
    "# choose components\n",
    "alphabet = iter(list(string.ascii_uppercase))\n",
    "alphabet_sL = iter(list(string.ascii_uppercase))\n",
    "alphabet_wS = iter(list(string.ascii_uppercase))\n",
    "version = iter(range(1,100))\n",
    "comps_todo = [\n",
    "    {'g':'gWeaLag2Weight', 'sL':'sLWea', 'wS':'wS100nnQrSST', 'Emu':'Emu0', 'name':'main','l':next(alphabet),'c':'c', 'v':'main', 'vc':''},\n",
    "    ]\n",
    "# for i,g in enumerate(['gWea', 'gWeaLag2', 'gnnWeaSST']):\n",
    "    # comps_todo.append({'g':g, 'sL':'sLWea', 'wS':'wS100nnQrSST', 'Emu':'Emu0', 'name':'formation: '+comp_names[g],'l':next(alphabet),'c':'m', 'v':'v%s' %(next(version)), 'vc':'vG%s' %(i)})\n",
    "for i,sL in enumerate(['sLAll','sLWeaNeigh']):\n",
    "    comps_todo.append({'g':'gWeaLag2Weight', 'sL':sL, 'wS':'wS100nnQrSST', 'Emu':'Emu0', 'name':'duration: '+comp_names[sL],'l':next(alphabet),'c':'orange', 'v':'v%s' %(next(version)), 'vc':'vD%s' %(i)})\n",
    "for i,wS in enumerate(['wS100nn','wS20nn','wS100nnNoSST','wS100nnQrSSTnoWeather','wS100nnQrSSTnoHist']):\n",
    "    # for i,wS in enumerate(['wS20nn','wS50nn','wS100nn'][::-1]):\n",
    "    comps_todo.append({'g':'gWeaLag2Weight', 'sL':'sLWea', 'wS':wS, 'Emu':'Emu0', 'name':'intensification: '+comp_names[wS],'l':next(alphabet),'c':'r', 'v':'v%s' %(next(version)), 'vc':'vI%s' %(i)})\n",
    "N = 1000\n",
    "overwrite = False\n",
    "validations = {}\n",
    "for dt in comps_todo:\n",
    "    tag = '_'.join([dt[k] for k in ['g','sL','wS','Emu']])\n",
    "    print(tag)\n",
    "    import _emulator; importlib.reload(_emulator); from _emulator import *\n",
    "    for k,v in {k:v for k,v in dt.items() if k in ['g','sL','wS','Emu']}.items():\n",
    "        exec(\"import %s; importlib.reload(%s); from %s import *\" % tuple(['components.'+k+'.'+v]*3))\n",
    "    for test_period in [tt for tt in train_test.columns if tt != 'year']:\n",
    "        train_years = train_test.loc[train_test[test_period]=='train', 'year'].values\n",
    "        test_years = train_test.loc[train_test[test_period]=='test', 'year'].values\n",
    "        train_folder = atl._dir_lvl4 + '/emulator/' + str(test_period)+'/'\n",
    "        # genesis\n",
    "        comp_file = train_folder+'/_comp_g_'+dt['g']+'/genesis_obj.pkl'\n",
    "        if os.path.isfile(comp_file) and overwrite == False:\n",
    "            genesis_obj = pickle.load(open(comp_file, 'rb'))\n",
    "        else:\n",
    "            genesis_obj = genesis_pred(dir=train_folder+'/_comp_g_'+dt['g']+'/', df=genesis.loc[np.isin(genesis.time.dt.year,train_years)])\n",
    "            genesis_obj.fit(atl)\n",
    "            genesis_obj.save()\n",
    "            # print(genesis_obj._probs)\n",
    "        # stormLength\n",
    "        comp_file = train_folder+'/_comp_sL_'+dt['sL']+'/end_obj.pkl'\n",
    "        if os.path.isfile(comp_file) and overwrite == False:\n",
    "            stormL_obj = pickle.load(open(comp_file, 'rb'))\n",
    "        else:\n",
    "            stormL_obj = storm_length_estimator(dir=train_folder+'/_comp_sL_'+dt['sL']+'/', atl=atl, tracks=tracks.loc[np.isin(tracks.year,train_years)])\n",
    "            stormL_obj.save()\n",
    "            stormL_obj.plot_simulated_storm_length(atl=atl, tracks=tracks.loc[np.isin(tracks.year,train_years)])\n",
    "        # windSpeed\n",
    "        comp_file = train_folder+'/_comp_wS_'+dt['wS']+'/wind_obj.pkl'\n",
    "        if os.path.isfile(comp_file) and overwrite == False:\n",
    "            wind_obj = pickle.load(open(comp_file, 'rb'))\n",
    "        else:\n",
    "            wind_obj = wind_estimator(dir=train_folder+'/_comp_wS_'+dt['wS']+'/', df=tracks.loc[np.isin(tracks.year,train_years)])\n",
    "            wind_obj.get_analogue_pdfs(atl=atl)\n",
    "            wind_obj.load_pdfs()\n",
    "            wind_obj.save()\n",
    "        exec(\"import %s; importlib.reload(%s); from %s import *\" % tuple(['components.wS._helping_functions']*3))\n",
    "        quantiles, wind_quR_params = sst_vs_wind_quantile_regression(tracks.loc[np.isin(tracks.year,train_years)], plot_dir=train_folder+'/_comp_wS_'+dt['wS']+'/', sst_var='sst')\n",
    "        # print(wind_obj._lr)\n",
    "        # wind_obj.plot_pdfs()\n",
    "        emu = storm_emulator(dir=train_folder, tag=tag, emulate_season_function=emulate_season_function)\n",
    "        atl._vector_time.values = np.array([str(d)[:10] for d in atl._vector_time.values], np.datetime64)\n",
    "        # emu.prepare_input(atl, sst_tropics, sst_MDR_rel, years, fileName = atl._dir_lvl4 + '/emulator/weather_sst_input.csv', overwrite=overwrite)\n",
    "        emu._weather_sst = weather_sst\n",
    "        emu.emulate_seasons_serial(genesis_obj, wind_obj, stormL_obj, years=test_years, N=N, overwrite=overwrite)\n",
    "    emu = storm_emulator(dir=atl._dir_lvl4 + '/emulator/xValid/', tag=tag, emulate_season_function=None)\n",
    "    emu._seasons = {}\n",
    "    for test_period in [tt for tt in train_test.columns if tt != 'year']:\n",
    "        test_years = train_test.loc[train_test[test_period]=='test', 'year'].values\n",
    "        for test_year in test_years:\n",
    "            with open(atl._dir_lvl4 + '/emulator/'+test_period+'/'+tag+'/sim/'+tag+'_'+str(test_year)+'_N'+str(N)+'.pkl', 'rb') as infile:\n",
    "                emu._seasons[test_year] = pickle.load(infile)\n",
    "    emu._N = N\n",
    "    emu._weather_sst = weather_sst\n",
    "    # emu.get_simu_tracks(overwrite=True)\n",
    "    # emu.get_other_stats_for_tracks(tracks)\n",
    "    emu.get_stats_seasonal_simu(overwrite=False)\n",
    "    emu.get_stats_seasonal_obs(tracks, train_test.year.values)\n",
    "    emu._sets = [{'years':[years], 'label':'xValid', 'color':'c'}]\n",
    "    emu._indicator_dict = {\n",
    "        'genesis' : 'storm formations',\n",
    "        'storm_days' : 'storm days in season',\n",
    "        'wind' : 'max. daily wind speed',\n",
    "        'wind' : 'acc. daily max. wind speeds',\n",
    "        'ACE' : 'ACE',\n",
    "        'Hur' : 'hurricanes',\n",
    "        'MajHur' : 'major hurricanes',\n",
    "        'stoMaxWind' : 'max. intensity of storm [kts]',\n",
    "        'stoLen' : 'storm duration',\n",
    "        'stoD' : 'day of storm',\n",
    "        'dWind' : 'change in storm intensity [kts]',\n",
    "        'wind_before' : 'intensity on the day before',\n",
    "        'sst' : 'SST',\n",
    "    }\n",
    "    if tag == 'gWeaLag2Weight_sLWeaNeigh_wS100nnQrSST_Emu0':\n",
    "        # fig 3\n",
    "        axes_ = []\n",
    "        fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(8,5), sharex=True)\n",
    "        for indicator,letter,ylim,ax in zip(['genesis','storm_days','MajHur','ACE', 'Hur'],['A','B','C','D','E'],[(0,30),(0,200),(0,10),(0,350),(0,16)], axes.flatten()):\n",
    "            ax = emu.vali_year_to_year_variability(indicator, show_legend=False, ax=ax)\n",
    "            ax.annotate(letter, xy=(0.05,0.95), xycoords='axes fraction', ha='left', va='top', fontweight='bold', fontsize=12, backgroundcolor='w')\n",
    "            corr_ = 'corr: %.2f%s' %(emu._validation[indicator]['pearson_median']['coef'],siggi(emu._validation[indicator]['pearson_median']['pval']))\n",
    "            ax.annotate(corr_, xy=(0.95,0.95), xycoords='axes fraction', ha='right', va='top', fontweight='bold', fontsize=12, backgroundcolor='w')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(emu._dir_plot+'fig3.png', dpi=300)\n",
    "\n",
    "\n",
    "    if dt['sL'] != 'sLWeaNeigh' or tag == 'gWeaLag2Weight_sLWeaNeigh_wS100nnQrSST_Emu0':\n",
    "        letter_ = next(alphabet_sL)\n",
    "\n",
    "        storms = [[np.float(w) for w in tracks.loc[(tracks.storm==storm), 'wind']] for storm in np.unique(tracks.loc[np.isin(tracks.year,years),'storm'])]\n",
    "        seasons = [winds for season in emu._seasons.values() for storms in season for winds in storms.values()]\n",
    "        \n",
    "        # HIST #\n",
    "        out_file = emu._dir_plot+'hist_duration_N'+str(emu._N)+'.png'\n",
    "        if os.path.isfile(out_file.replace('.png','.pkl')) and False:\n",
    "            fig, ax = pickle.load(open(out_file.replace('.png','.pkl'),'rb'))\n",
    "        else:\n",
    "            obs = np.array([len(winds) for winds in storms])\n",
    "            simu = np.array([len(winds) for winds in seasons])\n",
    "            fig, ax, out_file = emu.vali_distr_tests(obs=obs, simu=simu, out_file=out_file, indicator='duration', bins=np.arange(0,30,1))\n",
    "            pickle.dump((fig,ax), open(out_file.replace('.png','.pkl'), 'wb'))\n",
    "        ax.set_xlabel('storm duration [days]')\n",
    "        nicer_plot(fig,ax,out_file.replace('.png','_sens.png'), upper_left=letter_, upper_right=dt['name'], edgeC=dt['c'])\n",
    "\n",
    "\n",
    "    version_text = '\\n'.join(['%s: %s' %(comp_names[k],comp_names[dt[k]]) for k in ['g','sL','wS']])\n",
    "    for indicator,ylim in zip(['genesis','storm_days','Hur','MajHur','ACE'],[(0,35),(0,220),(0,18),(0,12),(0,360)]):\n",
    "        # Year to Year and correlation #\n",
    "        fig,ax,out_file = emu.vali_year_to_year_variability(indicator, show_legend=False)\n",
    "        vali = emu._validation[indicator]\n",
    "        text = 'pearson corr.: %s%s' %(vali['pearson_mean']['coef'].round(2), siggi(vali['pearson_mean']['pval']))\n",
    "        text += '\\nspearman corr.: %s%s' %(vali['spearman_mean']['coef'].round(2), siggi(vali['spearman_mean']['pval']))\n",
    "        nicer_plot(fig,ax,out_file.replace('.png','_sens.png'), ylim=ylim, text=text)\n",
    "    for indicator,ylim in zip(['genesis','storm_days','MajHur','ACE', 'Hur'],[(-16,16),(-120,120),(-7,7),(-240,240),(-10,10)]):\n",
    "        # trend in residuals #\n",
    "        fig,ax,out_file = emu.vali_residuals_and_long_term_trend(indicator)\n",
    "        vali = emu._validation[indicator]\n",
    "        text = 'MannKendall: %s%s' %(vali['MK_mean']['trend'], siggi(vali['MK_mean']['pval']))\n",
    "        text += '\\nLinear trend: %s%s' %(vali['trend_mean']['slope'].round(2), siggi(vali['trend_mean']['pval']))\n",
    "        nicer_plot(fig,ax,out_file.replace('.png','_sens.png'), ylim=ylim, text=text)\n",
    "\n",
    "        # RMSD\n",
    "        emu.vali_RMSD(indicator)\n",
    "\n",
    "    # residuals vs SST \n",
    "    for indicator,ylim in zip(['genesis','storm_days','MajHur','ACE', 'Hur'],[(-16,16),(-120,120),(-7,7),(-240,240),(-10,10)]):\n",
    "        fig,ax,out_file = emu.vali_residuals_IND_vs_SST(indicator, sst_MDR.groupby('time.year').mean('time'))\n",
    "        vali = emu._validation[indicator]\n",
    "        text = 'MannKendall: %s%s' %(vali['MK_vs_SST_median']['trend'], siggi(vali['MK_vs_SST_median']['pval']))\n",
    "        text += '\\nLinear regression: %s%s' %(vali['trend_vs_SST_median']['slope'].round(2), siggi(vali['trend_vs_SST_median']['pval']))\n",
    "        nicer_plot(fig,ax,out_file.replace('.png','_sens.png'), ylim=ylim, text=text)\n",
    "\n",
    "    if dt['wS'] != 'wS100nnQrSST' or tag == 'gWeaLag2Weight_sLWeaNeigh_wS100nnQrSST_Emu0':\n",
    "        #####################\n",
    "        # deviations in KNN #\n",
    "        #####################\n",
    "        for var,ylim,xlim in zip(['wind_before','sst'],[(-100,40),(-0.5,0.5)],[(0,160),(27,29)]):\n",
    "            plt.close('all')\n",
    "            fig,ax = plt.subplots(nrows=1, figsize=(4,3))\n",
    "            dists = xr.open_dataset(train_folder+'/_comp_wS_'+dt['wS']+'/distances.nc')['distances']          \n",
    "            if var in dists.dims:\n",
    "                for weather in [15,6,1,12]:\n",
    "                    y = dists.sel({'q':[17,50,83],'d':var}).squeeze()\n",
    "                    if 'weather_0' in dists.dims:\n",
    "                        y = y.sel({'weather_0':weather})\n",
    "                    for k in [k for k in y.dims if k not in [var,'q']]:\n",
    "                        y = y.mean(k)\n",
    "                    ax.fill_between(dists[var], y.loc[:,17], y.loc[:,83], alpha=0.5)\n",
    "                    ax.plot(dists[var], y.loc[:,50], label='w%s' %(weather))\n",
    "                ax.set_ylabel('bias in \\n'+emu._indicator_dict[var])\n",
    "                ax.set_xlabel(emu._indicator_dict[var])\n",
    "                ax.legend()\n",
    "                ax.set_xlim(xlim)\n",
    "                out_file = train_folder+'/_comp_wS_'+dt['wS']+'/dist_weather_'+var+'.png'\n",
    "                nicer_plot(fig,ax,out_file.replace('.png','_sens.png'), ylim=ylim)\n",
    "                # nicer_plot(fig,ax,out_file.replace('.png','_sens.png'), ylim=ylim, upper_left=letter_, upper_right=dt['vc'], edgeC=dt['c'])\n",
    "    \n",
    "    validations[tag] = emu._validation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_main",
   "language": "python",
   "name": "py_main"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "name": "2_emulations.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
